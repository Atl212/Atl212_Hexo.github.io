<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>某类幂函数不定积分的步骤</title>
    <url>/Atl212_Hexo.github.io/posts/23601/</url>
    <content><![CDATA[<p>$$<br>\int x^{α}dx &#x3D; \int \frac{x^{α+1}}{α+1}+c(α\neq-1)<br>$$</p>
<p>我们知道幂函数的不定积分公式一般都可以表示为这个式子（除了指数等于-1），但是如果每次都按照式子的步骤来写就会感到麻烦。</p>
<p>当α是整数时候还好，如果α是”分数”或者是”负数”或者是”负数的分数”时候，因为分母的系数是在下方所以要除了算出来外，最后还要倒过来。</p>
<p>特别是负数的分数如 -（1 &#x2F; 2）时，-（1 &#x2F; 2）+ 1 &#x3D; （1 &#x2F; 2）倒过来系数为2，本人在因为在运算中跳步错过几次，吃了亏。</p>
<p>那么有没有更简洁的方法，保证我们运算简单点并且保证准确性。</p>
<span id="more"></span> 

<p>通过观察式子我们可以发现，幂函数的指数和系数是一样的，都是α + 1，不同在于系数要倒过来。所以运算时我们可以这样。</p>
<p>$$<br>\int x^{α}dx \rightarrow x^{α+1} \rightarrow \frac{1}{α+1}x^{α+1}+c<br>$$</p>
<p>先写出指数加一得到的数，然后把得到的指数倒过来就变成了前面的系数。举例子：</p>
<p>$$<br>\int x^{-\frac{1}{2}}dx \rightarrow x^{\frac{1}{2}} \rightarrow 2x^{\frac{1}{2}}+c<br>$$</p>
<p>$$<br>\int x^{-\frac{4}{3}}dx \rightarrow x^{-\frac{1}{3}} \rightarrow -3x^{-\frac{1}{3}}+c<br>$$</p>
<p>写出来后不要忘记加c即可。</p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>高等数学</tag>
        <tag>不定积分</tag>
      </tags>
  </entry>
  <entry>
    <title>《白话机器学习的数学》正则化实现代码</title>
    <url>/Atl212_Hexo.github.io/posts/26314/</url>
    <content><![CDATA[<p>实现代码：</p>
<span id="more"></span> 

<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br> <br><span class="hljs-comment"># 真正的函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">g</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0.1</span> * (x ** <span class="hljs-number">3</span> + x ** <span class="hljs-number">2</span> + x)<br> <br><span class="hljs-comment"># 随意准备一些向真正的函数加入了一点噪声的训练数据</span><br>train_x = np.linspace (-<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">8</span>)<br>train_y =g(train_x)+ np.random.randn(train_x.size) * <span class="hljs-number">0.05</span><br> <br><span class="hljs-comment"># 绘图确认</span><br>x = np.linspace(-<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">100</span>)<br>plt.plot(train_x, train_y, <span class="hljs-string">&#x27;o&#x27;</span>)<br>plt.plot(x, g(x), linestyle = <span class="hljs-string">&#x27;dashed&#x27;</span>)<br>plt.ylim(-<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>plt.show()<br> <br><span class="hljs-comment">##########</span><br> <br><span class="hljs-comment"># 标准化</span><br>mu = train_x.mean ()<br>sigma = train_x.std()<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">standardize</span> (x):<br>    <span class="hljs-keyword">return</span> (x - mu)/ sigma<br> <br>train_z = standardize(train_x)<br> <br><span class="hljs-comment"># 创建训练数据的矩阵</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">to_matrix</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> np.vstack([ <br>        np.ones(x.size),<br>        x,    <br>        x ** <span class="hljs-number">2</span>,<br>        x ** <span class="hljs-number">3</span>,<br>        x ** <span class="hljs-number">4</span>,<br>        x ** <span class="hljs-number">5</span>,<br>        x ** <span class="hljs-number">6</span>,<br>        x ** <span class="hljs-number">7</span>,                                           <br>        x ** <span class="hljs-number">8</span>,<br>        x ** <span class="hljs-number">9</span>, <br>        x ** <span class="hljs-number">10</span>,<br>        ]).T <br> <br>X = to_matrix(train_z)<br> <br><span class="hljs-comment">#参数初始化</span><br>theta= np.random.randn(X.shape[<span class="hljs-number">1</span>])<br> <br><span class="hljs-comment"># 预测函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span> (x):<br>    <span class="hljs-keyword">return</span> np.dot (x,theta)<br> <br><span class="hljs-comment">##########</span><br> <br><span class="hljs-comment"># 目标函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">E</span>(<span class="hljs-params">x, y</span>):<br>     <span class="hljs-keyword">return</span> <span class="hljs-number">0.5</span> * np.<span class="hljs-built_in">sum</span>((y - f(x)) ** <span class="hljs-number">2</span>)<br> <br><span class="hljs-comment"># 学习率</span><br>ETA = <span class="hljs-number">1e-4</span><br> <br><span class="hljs-comment"># 误差</span><br>diff = <span class="hljs-number">1</span><br><span class="hljs-comment"># 重复学习</span><br>error = E(X,train_y)<br><span class="hljs-keyword">while</span> diff &gt; <span class="hljs-number">1e-6</span>:<br>    theta= theta - ETA * np.dot(f(X) - train_y,X)<br>    current_error = E(X,train_y)<br>    diff = error - current_error<br>    error = current_error<br>    <br><span class="hljs-comment"># 对结果绘图</span><br>z = standardize(x)<br>plt.plot(train_z, train_y, <span class="hljs-string">&#x27;o&#x27;</span>)<br>plt.plot(z, f(to_matrix(z)))<br>plt.show()<br> <br><span class="hljs-comment">##########</span><br> <br><span class="hljs-comment"># 保存未正则化的参数，然后再次参数初始化</span><br>theta1 = theta<br>theta = np.random.randn(X.shape[<span class="hljs-number">1</span>])<br> <br><span class="hljs-comment"># 正则化常量</span><br>LAMBDA = <span class="hljs-number">1</span><br> <br><span class="hljs-comment">#误差</span><br>diff = <span class="hljs-number">1</span><br> <br><span class="hljs-comment">#重复学习（包含正则化项）</span><br>error = E(X, train_y)<br><span class="hljs-keyword">while</span> diff &gt; <span class="hljs-number">1e-6</span>:<br>    <span class="hljs-comment"># 正则化项。偏置项不适用正则化，所以为 0</span><br>    reg_term = LAMBDA * np.hstack([<span class="hljs-number">0</span>, theta[<span class="hljs-number">1</span>:]])<br>    <span class="hljs-comment"># 应用正则化项，更新参数</span><br>    theta = theta - ETA *(np.dot(f(X) - train_y,X)+ reg_term) <br>    current_error = E(X, train_y)<br>    diff = error - current_error<br>    error = current_error<br> <br><span class="hljs-comment"># 对结果绘图</span><br>plt.plot(train_z,train_y,<span class="hljs-string">&#x27;o&#x27;</span>)<br>plt.plot(z,f(to_matrix(z)))<br>plt.show()<br> <br><span class="hljs-comment">##########</span><br> <br><span class="hljs-comment"># 保存应用了正则化的参数</span><br>theta2 = theta<br> <br>plt.plot(train_z, train_y, <span class="hljs-string">&#x27;o&#x27;</span>)<br> <br><span class="hljs-comment"># 画出未应用正则化的结果</span><br>theta = theta1<br>plt.plot(z, f(to_matrix(z)), linestyle = <span class="hljs-string">&#x27;dashed&#x27;</span>)<br><span class="hljs-comment"># 画出应用了正则化的结果</span><br>theta = theta2<br>plt.plot(z, f(to_matrix(z)))<br> <br>plt.show()<br></code></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Python</tag>
        <tag>正则化</tag>
        <tag>代码</tag>
      </tags>
  </entry>
  <entry>
    <title>部署网站关键</title>
    <url>/Atl212_Hexo.github.io/posts/2fb41cbd/</url>
    <content><![CDATA[<p>一个就是，这个 Github Action 的 deploy 配置脚本里面，其实也并不需要这个什么 hexo 部署的代码。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">- name: Generate static pages<br>  run: |<br>    hexo clean<br>    hexo generate --debug<br>  working-directory: Blog<br></code></pre></td></tr></table></figure>

<p>这两个的意思我认为是在服务上面把你的 public 的下的代码给清空，然后再部署一遍。</p>
<p>但这样搞就会有点问题，因为从 git 中 pull 或用 npm 安装的有些模块或插件啥的，并不是所有都会被上传到仓库下面。</p>
<p>当然，具体可能可以看 gitignore 脚本，看看有哪些是被你忽视，不需要上传到仓库上面的。</p>
<span id="more"></span> 

<p>但是我目前也搞不懂，似乎有些插件或者是文件，如果已经被上传到仓库上，似乎就不受这个 gitignore 给影响了？</p>
<p>所以虽然好像你确实有一部分 gitignore 里面是不会上传的，但是可能又还是有一部分会上传的。</p>
<p>所以如果你不是用你在本地已经部署好的 public 的静态文件的话，那么你 push 到仓库上面再 clean 又 generate 一次的话。</p>
<p>就会导致你不晓得什么东西是 push 到了仓库上，又有什么是没有 push 上去，从而最终在服务器上 generate 生成的静态文件可能是缺失，或者是跟你本地部署的不一致的。</p>
<p>比如说网上有些说为什么 next 主题没有上传到仓库上面导致 public 生成的 index.html 为空。</p>
<p>或者比如刚才我被折磨了几个小时，也搞不明白为什么本地部署的 hexo-next-darkmode 的 html 代码跟上传到服务器再重新生成的不一样。</p>
<p>所以搞了这么一圈，虽然我不晓得为什么其他有些人在 deploy.yaml 里面还要再重新生成一边，可能他们直接把全部 node_modules 都直接上传到仓库上了，所以也不在乎？</p>
<p>但是我看了看，这如果要把全部插件和模块都得推送到仓库上面，好说好歹也有50多mb，而且你也晓不得除了这个 node_modules 外有是不是还会有其他路径的文件还会影响到 public 静态文件的生成的。</p>
<p>反正我就直接把 gitignore 中的 &#x2F;public 给删掉了，省的又在服务器上重新生成一次。</p>
<p>我也不晓得为什么有些其他文章会按照奇奇怪怪的方式去部署网站，</p>
<p>但我感觉我能够晓得的就是，这帮人多多少少可能并没有搞懂这个网站部署的前前后后的一些指令或代码到底是干什么的。</p>
<p>但总之，先抄了跑了再说，反正有个所谓网站也是足够的了，也就不管了。</p>
<p>至于是否会有什么问题，又是否会出现些不知道的错误，那么就交给后人的，或者是其他人的智慧了。</p>
]]></content>
      <categories>
        <category>tmp</category>
      </categories>
      <tags>
        <tag>tmp</tag>
      </tags>
  </entry>
  <entry>
    <title>Github Action</title>
    <url>/Atl212_Hexo.github.io/posts/62980/</url>
    <content><![CDATA[<span id="more"></span> 

<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>前几天试着搭了hexo博客，本来部署直接用 hexo d 命令进行的部署。</p>
<p>但是自己更习惯用 github desktop。可以自定义 commit 的名称，也可以更直观看到文件的修改情况，所以试着用 github action 部署博客。</p>
<p>由于本人没怎么用过 action 部署，同时对于 git 拉取下来的一些文件设置也有认识不足，在此记录下部署过程遇到的几个问题。</p>
<p>hexo generate –debug</p>
<h2 id="yaml文件路径配置问题"><a href="#yaml文件路径配置问题" class="headerlink" title="yaml文件路径配置问题"></a>yaml文件路径配置问题</h2><h2 id="尝试构建但出现-Permission-denied"><a href="#尝试构建但出现-Permission-denied" class="headerlink" title="尝试构建但出现 Permission denied"></a>尝试构建但出现 Permission denied</h2><h2 id="部署成功但index-html文件大小为0"><a href="#部署成功但index-html文件大小为0" class="headerlink" title="部署成功但index.html文件大小为0"></a>部署成功但index.html文件大小为0</h2>]]></content>
      <categories>
        <category>Github</category>
      </categories>
      <tags>
        <tag>Github</tag>
        <tag>Action</tag>
        <tag>部署</tag>
        <tag>路径</tag>
      </tags>
  </entry>
</search>
